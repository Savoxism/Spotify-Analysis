{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.decomposition import PCA, KernelPCA, TruncatedSVD\n",
    "from sklearn.manifold import Isomap, TSNE, MDS\n",
    "import random\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "import warnings \n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/genres_v2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop([\"type\",\"type\",\"id\",\"uri\",\"track_href\",\"analysis_url\",\"song_name\",\n",
    "                \"Unnamed: 0\",\"title\", \"duration_ms\", \"time_signature\"], axis =1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(df[\"genre\"])\n",
    "_ = plt.xticks(rotation=90)\n",
    "_ = plt.title(\"Genres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where genre is \"Pop\"\n",
    "df = df[df['genre'] != \"Pop\"].reset_index(drop=True)\n",
    "\n",
    "# Identify numeric columns\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Calculate correlation for numeric columns only\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "\n",
    "correlation_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10,9))\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.loc[:, :\"tempo\"]\n",
    "y = df[\"genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "plt.figure(figsize = (18,14))\n",
    "for i in x.columns:\n",
    "    plt.subplot(4,4, k + 1)\n",
    "    sns.distplot(x[i])\n",
    "    plt.xlabel(i, fontsize=11)\n",
    "    k +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y,test_size= 0.2, random_state=42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the Data (MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "col = xtrain.columns\n",
    "scalerx = MinMaxScaler()\n",
    "xtrain = scalerx.fit_transform(xtrain)\n",
    "xtest = scalerx.transform(xtest)\n",
    "xtrain = pd.DataFrame(xtrain, columns = col)\n",
    "xtest = pd.DataFrame(xtest, columns = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "ytrain = le.fit_transform(ytrain)\n",
    "ytest = le.transform(ytest)\n",
    "x = pd.concat([xtrain, xtest], axis = 0)\n",
    "y = pd.concat([pd.DataFrame(ytrain), pd.DataFrame(ytest)], axis = 0)\n",
    "\n",
    "y_train = le.inverse_transform(ytrain)\n",
    "y_test = le.inverse_transform(ytest)\n",
    "y_org = pd.concat([pd.DataFrame(y_train), pd.DataFrame(y_test)], axis = 0)\n",
    "np.unique(y_train)\n",
    "plt.subplots(figsize=(8,6))\n",
    "ax = sns.heatmap(xtrain.corr()).set(title = \"Correlation between Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "PCA is a popular dimensionality reduction approach that may assist in decreasing the complexity of large datasets and increasing the performance of machine learning models.\n",
    "\n",
    "With input data x, the algorithm uses PCA to minimize the number of features to two parts that explain the variation. The reduced Dataset is shown on a 2D scatter plot, with dots colored by class labels in y. This aids in visualizing the dividing of some classes in the reduced feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "x_pca = pca.fit_transform(x, y)\n",
    "plot_pca = plt.scatter(x_pca[:,0], x_pca[:,1], c=y)\n",
    "handles, labels = plot_pca.legend_elements()\n",
    "lg = plt.legend(handles, list(np.unique(y_org)), loc = 'center right', bbox_to_anchor=(1.4, 0.5))\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "_ = plt.title(\"PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE\n",
    "\n",
    "t-SNE is a popular nonlinear dimensionality reduction approach that may assist in decreasing the complexity of large datasets and improve the performance of machine learning models.\n",
    "\n",
    "Using t-Distributed Stochastic Neighbor Embedding (t-SNE) on the input data x reduces the number of features in the high-dimensional space to 2D while maintaining similarity between Data points.\n",
    "\n",
    "A 2D scatter plot shows the reduced Dataset, with dots colored according to their y-class labels. It helps visualize the division of some classes in the reduced feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "x_tsne = tsne.fit_transform(x, y)\n",
    "plot_tsne = plt.scatter(x_tsne[:,0], x_tsne[:,1], c=y)\n",
    "handles, labels = plot_tsne.legend_elements()\n",
    "lg = plt.legend(handles, list(np.unique(y_org)), loc = 'center right', bbox_to_anchor=(1.4, 0.5))\n",
    "plt.xlabel(\"T-SNE 1\")\n",
    "plt.ylabel(\"T-SNE 2\")\n",
    "_ = plt.title(\"T-SNE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD\n",
    "\n",
    "SVD is a popular dimensionality reduction approach that may assist in decreasing the complexity of large datasets and increasing the performance of machine learning models.\n",
    "\n",
    "The following code applies Singular Value Decomposition (SVD) on the input data x with n components=2, reducing the number of input features to two that explain the most variance in the data. The reduced Dataset is then shown on a 2D scatter plot, with the dots colored based on their y-class labels.\n",
    "\n",
    "This facilitates visualizing the division of multiple classes in the reduced feature space, and the scatter plot is made with the matplotlib tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=2)\n",
    "x_svd = svd.fit_transform(x, y)\n",
    "plot_svd = plt.scatter(x_svd[:,0], x_svd[:,1], c=y)\n",
    "handles, labels = plot_svd.legend_elements()\n",
    "lg = plt.legend(handles, list(np.unique(y_org)), loc = 'center right', bbox_to_anchor=(1.4, 0.5))\n",
    "plt.xlabel(\"Truncated SVD 1\")\n",
    "plt.ylabel(\"Truncated SVD 2\")\n",
    "_ = plt.title(\"Truncated SVD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA\n",
    "\n",
    "LDA is a popular dimensionality reduction approach that can increase machine learning model performance by decreasing the influence of irrelevant information.\n",
    "\n",
    "The following code does Linear Discriminant Analysis (LDA) on the input data x with n components=2, which reduces the number of input features to two linear discriminants that maximize the division between the different classes in the data.\n",
    "\n",
    "The reduced Dataset is then shown on a 2D scatter plot, with the dots colored based on their y-class labels. This aids in visualizing the division of some classes in the reduced feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "x_lda = lda.fit_transform(x, y.values.ravel())\n",
    "plot_lda = plt.scatter(x_lda[:,0], x_lda[:,1], c=y)\n",
    "handles, labels = plot_lda.legend_elements()\n",
    "lg = plt.legend(handles, list(np.unique(y_org)), loc = 'center right', bbox_to_anchor=(1.4, 0.5))\n",
    "plt.xlabel(\"LDA 1\")\n",
    "plt.ylabel(\"LDA 2\")\n",
    "_ = plt.title(\"Linear Discriminant Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(\"Trap Metal\", \"Rap\")\n",
    "df = df.replace(\"Underground Rap\", \"Rap\")\n",
    "df = df.replace(\"Emo\", \"Rap\")\n",
    "df = df.replace(\"RnB\", \"Rap\")\n",
    "df = df.replace(\"Hiphop\", \"Rap\")\n",
    "df = df.replace(\"Dark Trap\", \"Rap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(8,6))\n",
    "ax = sns.histplot(df[\"genre\"])\n",
    "_ = plt.xticks(rotation=30)\n",
    "_ = plt.title('Genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_drop = [] \n",
    "\n",
    "for i in range(len(df)): \n",
    "  if df.iloc[i]['genre'] == 'Rap': \n",
    "    if random.random()<0.85: \n",
    "      rows_drop.append(i) \n",
    "df.drop(index = rows_drop, inplace=True) \n",
    "\n",
    "ax = sns.histplot(df[\"genre\"]) \n",
    "_ = plt.xticks(rotation=30) \n",
    "_ = plt.title(\"Genres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.loc[:, :\"tempo\"]\n",
    "y = df[\"genre\"]\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, \n",
    "                                                random_state=42, shuffle=True)\n",
    "\n",
    "col = xtrain.columns\n",
    "scalerx = MinMaxScaler()\n",
    "\n",
    "xtrain = scalerx.fit_transform(xtrain)\n",
    "xtest = scalerx.transform(xtest)\n",
    "\n",
    "xtrain = pd.DataFrame(xtrain, columns=col)\n",
    "xtest = pd.DataFrame(xtest, columns=col)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "ytrain = le.fit_transform(ytrain)\n",
    "ytest = le.transform(ytest)\n",
    "\n",
    "x = pd.concat([xtrain, xtest], axis=0)\n",
    "y = pd.concat([pd.DataFrame(ytrain), pd.DataFrame(ytest)], axis=0)\n",
    "\n",
    "y_train = le.inverse_transform(ytrain)\n",
    "y_test = le.inverse_transform(ytest)\n",
    "y_org = pd.concat([pd.DataFrame(y_train), pd.DataFrame(y_test)], axis=0)\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping1 = keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                patience=10, restore_best_weights=True)\n",
    "early_stopping2 = keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", \n",
    "                                                patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(xtrain.shape[1],)),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(len(np.unique(ytrain)), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = keras.optimizers.Adam(),\n",
    "            loss = \"sparse_categorical_crossentropy\",\n",
    "            metrics = [\"accuracy\"])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(xtrain, ytrain,\n",
    "                epochs = 100,\n",
    "                verbose = 1, batch_size = 128,\n",
    "                validation_data = (xtest, ytest),\n",
    "                callbacks = [early_stopping1, early_stopping2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(xtrain, ytrain))\n",
    "print(model.evaluate(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history[\"loss\"])\n",
    "plt.plot(model_history.history[\"val_loss\"])\n",
    "plt.legend([\"loss\", \"validation loss\"], loc =\"upper right\")\n",
    "plt.title(\"Train and Validation Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Sparse Categorical Cross Entropy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history[\"accuracy\"])\n",
    "plt.plot(model_history.history[\"val_accuracy\"])\n",
    "plt.legend([\"accuracy\", \"validation accuracy\"], loc =\"upper right\")\n",
    "plt.title(\"Train and Validation Accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(xtest).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = metrics.confusion_matrix(ytest, ypred)\n",
    "_ = sns.heatmap(cf_matrix, fmt=\".0f\", annot=True)\n",
    "_ = plt.title(\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(ytest, ypred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
